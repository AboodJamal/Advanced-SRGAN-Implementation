# ğŸ“¸ SRGAN: Super-Resolution Generative Adversarial Network (4Ã— Upscaling)

> **Authors**: Abdallah Jamal Al-Harrem, Hossam Shehadeh
> **Project Type**: Advanced Deep Learning | Computer Vision
> **Focus**: 4Ã— Single Image Super-Resolution (SISR) for Facial & Natural Images

---

## ğŸŒŸ Super-Resolution in Action

> âš¡ _Before diving in, hereâ€™s what SRGAN can do..._

| Low Resolution          | SRGAN Output              | Real Image               |
| ----------------------- | ------------------------- | ------------------------ |
| ![](samples/lowcel.png)   | ![](samples/srgan.png)      | ![](samples/realcel.png)   |
| ![](samples/zebraLow.png) | ![](samples/Zebrasrgan.png) | ![](samples/zebraReal.png) |

## ğŸš€ Project Overview

This project presents a **dual-model SRGAN** system for **4Ã— single image super-resolution**. It aims to reconstruct high-quality, realistic high-resolution (HR) images from their low-resolution (LR) counterparts using a deep-learning-based perceptual framework.

Key innovations include:

- ğŸ§  **Two specialized models**:
  - Facial SRGAN trained on **CelebA**
  - General SRGAN trained on **DIV2K**
- âš™ï¸ **Two-stage training** with pixel-wise loss followed by adversarial fine-tuning
- ğŸ§ª **Multi-metric evaluation**: PSNR, SSIM, and LPIPS
- ğŸ”„ **Cross-domain generalization** analysis using Set14 benchmark

---

## ğŸ“‚ Datasets

| Dataset                                                 | Domain         | Purpose              | Samples                      |
| ------------------------------------------------------- | -------------- | -------------------- | ---------------------------- |
| [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) | Faces          | Facial SR model      | 30,000 images                |
| [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/)         | Natural images | General SR model     | 800 training, 100 validation |
| [Set14](https://github.com/jbhuang0604/SelfExSR)           | Mixed          | Evaluation benchmark | 14 standard images           |

---
## ğŸ—‚ï¸ Project Structure

```
SRGAN-Project/
â”‚
â”œâ”€â”€ README.md                    â† Project documentation
â”œâ”€â”€ requirements.txt             â† Python dependencies
â”œâ”€â”€ .gitignore                   â† Ignore checkpoints, logs, temp files
â”‚
â”œâ”€â”€ samples/                     â† Visual examples for README
â”‚   â”œâ”€â”€ lowcel.png
â”‚   â”œâ”€â”€ srgan.png
â”‚   â”œâ”€â”€ realcel.png
â”‚   â”œâ”€â”€ zebraLow.png
â”‚   â”œâ”€â”€ zebrasrgan.png
â”‚   â”œâ”€â”€ zebraReal.png
â”‚   â””â”€â”€ e1.png ... e5.png
â”‚
â”œâ”€â”€ docs/                        â† Architecture diagrams and documentation
â”‚   â”œâ”€â”€ generator_architecture.png
â”‚   â””â”€â”€ discriminator_architecture.png
â”‚
â”œâ”€â”€ src/                         â† Main source code and training notebooks
â”‚   â”œâ”€â”€ celeba/
â”‚   â”‚   â”œâ”€â”€ train_celeba.ipynb   â† CelebA SRGAN training pipeline
â”‚   â”‚   â”œâ”€â”€ logs/                â† Training logs (loss, metrics , PSNR, SSIM, etc.)
â”‚   â”‚   â””â”€â”€ models/              â† Checkpoints: best_psnr.pth, best_lpips.pth, etc.
â”‚   â”‚
â”‚   â””â”€â”€ div2k/
â”‚       â”œâ”€â”€ train_div2k.ipynb    â† DIV2K SRGAN training pipeline
â”‚       â”œâ”€â”€ logs/                â† Training logs (loss, metrics , PSNR, SSIM, etc.)
â”‚       â””â”€â”€ models/              â† Checkpoints:  best_psnr.pth, best_lpips.pth, etc.
â”‚
â””â”€â”€ reports/
    â”œâ”€â”€ SRGAN_Report_Format1.pdf
    â”œâ”€â”€ SRGAN_Report_Format2.pdf
```
---

## ğŸ§  Methodology and Architecture

### ğŸ” Two-Stage Training Strategy

The SRGAN system uses a robust two-stage training methodology to optimize both pixel accuracy and perceptual realism:

#### **Stage 1 â€“ SRResNet Pre-training**

- Generator trained independently using **L1 pixel loss**
- Establishes a strong baseline with high PSNR performance
- Provides stable initialization for GAN fine-tuning
- Runs for variable epochs until convergence

#### **Stage 2 â€“ Adversarial Fine-tuning**

- Joint training of **generator and discriminator**
- Uses a **multi-component loss function**:
  ```
   L_total = Î±Â·L_pixel + Î²Â·L_content + Î³Â·L_adv
  ```
- Incorporates adversarial feedback to enhance texture generation and realism

---

### ğŸ§  Generator Architecture (SRResNet-Based)

The generator follows a deep residual architecture optimized for perceptual super-resolution.

| Stage                   | Components                                                                                        |
| ----------------------- | ------------------------------------------------------------------------------------------------- |
| **Input Layer**   | `Conv(9Ã—9, 64) + PReLU`                                                                        |
| **Residual Body** | `16 Ã— ResidualBlock:` each block = `[Conv(3Ã—3, 64) + BN + PReLU] Ã— 2` with skip connection |
| **Post-Residual** | `Conv(3Ã—3, 64) + BN + Global Skip Connection`                                                  |
| **Upsampling**    | `2 Ã— SubPixelConv:` each block = `Conv(3Ã—3, 256) + PixelShuffle(2) + PReLU`                 |
| **Output Layer**  | `Conv(9Ã—9, 3) + Tanh`                                                                          |

ğŸ“ **Full Generator Diagram**

Click to zoom:

<a href="docs/generator_architecture.png" target="_blank">
  <img src="docs/generator_architecture.png" alt="Generator Architecture Diagram" width="600"/>
</a>

Or click the link to view the full-resolution image directly:  
â¡ï¸ [Generator Architecture](samples/generator_architecture.png)





**Key Design Choices:**

- âœ… **16 Residual Blocks**: Strong expressivity with efficient computation
- ğŸ” **Global Skip Connection**: Preserves low-frequency information
- ğŸ§  **PReLU Activation**: Avoids vanishing gradients in deep architectures
- ğŸŒ€ **Sub-pixel Convolution**: Efficient, learned 4Ã— upsampling
- âš–ï¸ **Batch Normalization**: Stabilizes training dynamics

---

### ğŸ›¡ï¸ Discriminator Architecture (VGG-Inspired)

The discriminator is designed for binary classification between real HR images and generated SR images.

| Stage                          | Components                                                        |
| ------------------------------ | ----------------------------------------------------------------- |
| **Input**                | 96Ã—96Ã—3 HR or SR image                                          |
| **Convolutional Blocks** | `8 Ã— ConvBlocks:`                                              |
|                                | Pattern :`[Conv(3Ã—3) + BN + LeakyReLU(0.2)]`                   |
|                                | Channels :`64 â†’ 128 â†’ 128 â†’ 256 â†’ 256 â†’ 512 â†’ 512 â†’ 512` |
|                                | Stride alternates between `1` and `2` for downsampling                      |
| **Global Avg Pooling**   | `AdaptiveAvgPool2d(6Ã—6)`                                       |
| **Classifier**           | `Linear(18432 â†’ 1024) + LeakyReLU â†’ Linear(1024 â†’ 1)`        |

ğŸ“ **Full Discriminator Diagram**

Click to zoom:

<a href="docs/discriminator_architecture.png" target="_blank">
  <img src="docs/discriminator_architecture.png" alt="Discriminator Architecture Diagram" width="600"/>
</a>

Or click the link to view the full-resolution image directly:  
â¡ï¸ [Discriminator Architecture](samples/discriminator_architecture.png)



**Architecture Rationale:**

- ğŸ¯ **Progressive Channel Growth**: Captures features from edges to textures
- â¡ï¸ **Strided Convolutions**: Replaces max-pooling for downsampling
- âš¡ **LeakyReLU Activations**: Prevents gradient dying in the discriminator
- ğŸ“ **Adaptive Pooling**: Ensures consistent feature shape across samples

### âš–ï¸ Loss Weights

- Pixel Loss `Î± = 1.0`
- Content Loss `Î² = 0.006`
- Adversarial Loss `Î³ = 0.001`

---

## ğŸ§  Evaluation Metrics

| Metric          | Description                                           |
| --------------- | ----------------------------------------------------- |
| **PSNR**  | Pixel-wise accuracy (dB)                              |
| **SSIM**  | Structural fidelity to ground truth                   |
| **LPIPS** | Learned perceptual similarity (deep feature distance) |

ğŸ“Œ Separate model checkpoints were saved for each metric to enable application-specific selection.

---

## ğŸ’¾ Comprehensive Checkpointing System

All training progress is tracked and saved through a robust checkpointing mechanism:

| Checkpoint File               | Description                                       |
| ----------------------------- | ------------------------------------------------- |
| `checkpoint_latest.pth`     | Latest training state (for resumption)            |
| `checkpoint_best_psnr.pth`  | Model with highest PSNR                           |
| `checkpoint_best_ssim.pth`  | Model with best SSIM score                        |
| `checkpoint_best_lpips.pth` | Model with lowest LPIPS (best perceptual quality) |
| `checkpoint_epoch_XX.pth`   | Periodic milestone checkpoints for traceability   |

> âœ… Supports training resumption, fine-tuning, and targeted deployment.

---

## ğŸ“ˆ Results Summary

### ğŸ§‘â€ğŸ¦± CelebA (Facial Super-Resolution)

| Model               | PSNR â†‘ | SSIM â†‘ | LPIPS â†“         |
| ------------------- | ------- | ------- | ---------------- |
| SRResNet (Baseline) | 42.70   | 0.9669  | 0.0833           |
| SRGAN (Best PSNR)   | 42.38   | 0.9642  | 0.0566           |
| SRGAN (Best LPIPS)  | 41.43   | 0.9572  | **0.0368** |

### ğŸŒ„ DIV2K (Natural Image Super-Resolution)

| Model                  | PSNR â†‘         | SSIM â†‘          | LPIPS â†“         |
| ---------------------- | --------------- | ---------------- | ---------------- |
| SRResNet (Baseline)    | 23.25           | 0.6576           | 0.3616           |
| SRGAN (Best PSNR/SSIM) | **25.15** | **0.7191** | 0.1901           |
| SRGAN (Best LPIPS)     | 24.80           | 0.7038           | **0.1577** |

---

## ğŸ” Insights & Takeaways

- ğŸ¨ **GANs significantly improve perceptual quality**, even with a small drop in PSNR.
- ğŸ” **CelebA-trained models generalize well** to natural images (Set14).
- ğŸ” **LPIPS outperforms PSNR** for visual similarity evaluation.
- ğŸ“‰ **Data diversity > data volume**: DIV2K (800 samples) > CelebA (24,000) on cross-domain generalization.
- ğŸ§  **Multi-metric optimization** enables application-specific deployment.

---

## ğŸ”­ Future Enhancements

- ğŸ“ˆ Progressive resolution scaling (for 4K+ upscaling)
- ğŸ§± Integrate **RRDB blocks** (ESRGAN) for better texture synthesis
- ğŸ§  Add **self-attention modules** to improve fine detail
- ğŸ§­ Saliency-aware cropping to generalize CelebA-style specialization

---

## ğŸ’¡ Applications

- ğŸ§‘â€ğŸ¦± **Facial image enhancement**
- ğŸ›°ï¸ **Satellite and aerial image sharpening**
- ğŸ§¬ **Medical image diagnostics**
- ğŸ–¼ï¸ **Upscaling low-res photos & videos**
- ğŸ§ª **Scientific imaging and restoration**

---

## ğŸ“š References

- Goodfellow et al. (2014) â€” *Generative Adversarial Networks*
- Ledig et al. (2017) â€” *Photo-Realistic SR using GANs (SRGAN)*
- Johnson et al. (2016) â€” *Perceptual Losses for SR*
- Zhang et al. (2018) â€” *LPIPS Metric*
- He et al. (2016) â€” *Residual Networks (ResNet)*

---

## ğŸ“ License & Acknowledgments

This project is open-source and provided for academic and research purposes.
Datasets and pre-trained networks are credited to their original authors.

---

## ğŸ“¸ Examples for some Images for all models

| Example       | -                 |
| ------------- | ----------------- |
| _Example 1_ | ![](samples/e1.png) |
| _Example 2_ | ![](samples/e2.png) |
| _Example 3_ | ![](samples/e3.png) |
| _Example 4_ | ![](samples/e4.png) |
| _Example 5_ | ![](samples/e5.png) |
